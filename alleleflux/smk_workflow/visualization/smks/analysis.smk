
# === DYNAMIC AGGREGATION FUNCTION ===
def get_tracking_targets(wildcards):
    """
    This function runs AFTER the checkpoint 'terminal_analysis' is complete.
    It reads the summary TSV generated by that rule to find the list of MAGs
    that need to be tracked.
    """
    # Get the output file from the checkpoint
    checkpoint_output = checkpoints.terminal_analysis.get(**wildcards).output.summary
    
    mags = []

    # Check if specific MAGs are configured
    specific_mags = config.get("specific_mags", [])
    if specific_mags:
        mags = specific_mags
    # If the file exists (it will after the checkpoint runs), read the MAG IDs
    elif os.path.isfile(checkpoint_output):
        try:
            df = pd.read_csv(checkpoint_output, sep="\t")
            # Extract unique MAG IDs
            mags = df[df["sites_processed"] > 0]["mag_id"].unique().tolist()
        except Exception as e:
            # Fallback if file is empty or corrupt
            print(f"Warning: Could not read checkpoint summary: {e}")
            return []
    
    if mags:
        # Expand the target file paths for these MAGs
        return expand(
            os.path.join(config["output_dir"], "track_freqs" ,"{mag_id}_frequency_table.tsv"),
            mag_id=mags
        )

    # If file doesn't exist yet (e.g. dry run before checkpoint runs), return empty
    return []



checkpoint terminal_analysis:
    input:
        metadata = config["metadata"],
        sig_sites = config["significant_sites_file"],
        profile_dir = config["profile_dir"], 
    output:
        # The script generates a summary file. We use this as the target.
        summary = os.path.join(config["output_dir"], "terminal_nucleotide","terminal_nucleotide_analysis_summary.tsv"),
    params:
        out_dir = directory(os.path.join(config["output_dir"], "terminal_nucleotide")),
        group = config["analysis_params"]["group"],
        time = config["analysis_params"]["timepoint"],
        p_col = config["analysis_params"].get("p_value_column", "q_value"),
        p_val = config["analysis_params"].get("p_value_threshold", 0.05),
        test = config["analysis_params"].get("test_type", "two_sample_paired_tTest"),
        group_analyzed_arg = f"--group_analyzed {config['analysis_params']['group_analyzed']}" if config["analysis_params"].get("group_analyzed") else ""
    threads: config["cpus"]["threads_per_job"]
    shell:
        """
        alleleflux-terminal-nucleotide \
            --significant_sites {input.sig_sites} \
            --profile_dir {input.profile_dir} \
            --group {params.group} \
            --timepoint {params.time} \
            --metadata {input.metadata} \
            --output {params.out_dir} \
            --p_value_column {params.p_col} \
            --p_value_threshold {params.p_val} \
            --test-type {params.test} \
            {params.group_analyzed_arg} \
            --cpus {threads} \
            --log-level INFO
        """

# This rule runs once per MAG, after the checkpoint has identified valid MAGs.
rule track_allele_frequencies:
    input:
        metadata = METADATA_OUT,
        # We look for the specific MAG file inside the terminal analysis directory
        anchor_file = os.path.join(config["output_dir"], "terminal_nucleotide", "{mag_id}", "{mag_id}_terminal_nucleotides.tsv")
    output:
        # The python script generates two files: a wide table and a long table
        wide = os.path.join(config["output_dir"], "track_freqs" ,"{mag_id}_frequency_table.tsv"),
        long = os.path.join(config["output_dir"], "track_freqs" , "{mag_id}_frequency_table.long.tsv")
    params:
        out_dir = os.path.join(config["output_dir"], "track_freqs"),
        mag_id = "{mag_id}",
        anchor_col = config["tracking_params"]["anchor_column"],
        min_cov = config["tracking_params"]["min_cov_per_site"]
    threads: config["cpus"]["threads_per_job"]
    shell:
        """
        alleleflux-track-alleles \
            --mag-id {params.mag_id} \
            --anchor-file {input.anchor_file} \
            --metadata {input.metadata} \
            --output-dir {params.out_dir} \
            --anchor-column {params.anchor_col} \
            --min-cov-per-site {params.min_cov} \
            --cpus {threads} \
            --log-level INFO
        """