# AlleleFlux Configuration File
# ============================
# This file was generated by `alleleflux init`
# Edit the paths and parameters below to match your analysis setup.
#
# For detailed documentation, see: https://github.com/MoellerLabPU/AlleleFlux

run_name: "alleleflux_analysis"

# Input Files
# ------------
# Path specifications for all required input data
input:
  fasta_path: ""                  # Reference FASTA file (required)
  prodigal_path: ""               # Prodigal nucleic acid output (.fna) for the reference
  metadata_path: ""               # Sample metadata file with columns: sample_id, file_path, group, time
  gtdb_path: ""                   # GTDB taxonomy file (gtdbtk.bac120.summary.tsv)
  mag_mapping_path: ""            # MAG-to-contig mapping file with columns: mag_id, contig_id

# Output Directory
# ----------------
output:
  root_dir: "./alleleflux_output" # Root directory for all output files

log_level: "INFO"                 # Logging level: DEBUG, INFO, WARNING, ERROR

# Analysis Configuration
# ----------------------
# Core settings that control the type and scope of analysis
analysis:
  data_type: "longitudinal"       # "single" (one timepoint) or "longitudinal" (multiple timepoints)
  allele_analysis_only: False     # When True, only runs allele analysis and skips scoring/outlier detection

  # Enable/disable specific analysis modules
  use_lmm: True                   # Linear Mixed Models analysis
  use_significance_tests: True    # Two-sample and single-sample tests
  use_cmh: True                   # CMH test for categorical data

  # Timepoints and groups to analyze
  # For longitudinal analysis: specify pairs of timepoints and which one to focus on
  # For single analysis: specify individual timepoints
  timepoints_combinations:
    - timepoint: ["pre", "post"]  # Timepoint pair for longitudinal analysis
      focus: "post"               # Which timepoint is the "focus" for comparisons
    # - timepoint: ["end"]        # For single timepoint analysis (uncomment data_type: "single")

  groups_combinations:
    - ["treatment", "control"]    # Groups to compare (e.g., treatment vs control)

# Quality Control Parameters
# --------------------------
quality_control:
  min_sample_num: 4               # Minimum samples required for analysis
  breadth_threshold: 0.1          # Minimum coverage breadth (fraction of genome covered)
  coverage_threshold: 1           # Minimum average coverage depth to pass QC
  disable_zero_diff_filtering: False  # Keep sites with zero difference between groups

# Profiling Parameters
# --------------------
# Parameters for pileup generation during sample profiling
profiling:
  ignore_orphans: False           # Ignore orphan reads (without proper pairs)
  min_base_quality: 30            # Minimum base quality score to consider
  min_mapping_quality: 2          # Minimum mapping quality score to consider
  ignore_overlaps: True           # Ignore overlapping read segments

# Statistical Parameters
# ----------------------
statistics:
  filter_type: "t-test"           # Preprocessing filter: "t-test", "wilcoxon", or "both"
  preprocess_between_groups: True # Preprocess data for between-groups tests
  preprocess_within_groups: True  # Preprocess data for within-group tests
  max_zero_count: 4               # Maximum zeros allowed in single-sample test
  p_value_threshold: 0.05         # P-value threshold for significance
  fdr_group_by_mag_id: False      # Apply FDR correction per MAG
  min_positions_after_preprocess: 1  # Minimum positions after preprocessing

# dN/dS Analysis Parameters
# -------------------------
# Configuration for evolutionary rate analysis
dnds:
  p_value_column: "q_value"       # Column for filtering: "min_p_value" or "q_value"
  dn_ds_test_type: "two_sample_unpaired_tTest"  # Test type for filtering results

# Compute Resources
# -----------------
# Resources allocated to each workflow step
resources:
  cpus:
    threads_per_job: 16           # Threads for parallel jobs

  memory:                         # Memory in MB
    profile: 10000                # ~10 GB for profiling
    quality_control: 100000       # ~100 GB for quality control
    analyze_alleles: 100000       # ~100 GB for allele analysis
    significance_test: 100000     # ~100 GB for significance testing
    dn_ds: 200000                 # ~200 GB for dN/dS analysis

  time:                           # Runtime limits (HH:MM:SS format)
    profile: "08:00:00"           # 8 hours for profiling
    significance_test: "08:00:00" # 8 hours for significance tests
    general: "24:00:00"           # 24 hours for general tasks
