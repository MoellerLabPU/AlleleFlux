# AlleleFlux Configuration File
# ============================
# This file was generated by `alleleflux init`
# Edit the paths and parameters below to match your analysis setup.
#
# For detailed documentation, see: https://github.com/MoellerLabPU/AlleleFlux

run_name: "alleleflux_analysis"

# Input Files
# ------------
# Path specifications for all required input data
input:
  fasta_path: ""                  # Reference FASTA file (required)
  prodigal_path: ""               # Prodigal nucleic acid output (.fna) for the reference
  metadata_path: ""               # Sample metadata file with columns: sample_id, file_path, group, time
  gtdb_path: ""                   # GTDB taxonomy file (gtdbtk.bac120.summary.tsv)
  mag_mapping_path: ""            # MAG-to-contig mapping file with columns: mag_id, contig_id
  profiles_path: ""               # Optional: Path to pre-existing profiles directory
                                  # If provided, profiling step is skipped and these profiles are used
                                  # Useful for rerunning analysis with different parameters

# Output Directory
# ----------------
output:
  root_dir: "./alleleflux_output" # Root directory for all output files

log_level: "INFO"                 # Logging level: DEBUG, INFO, WARNING, ERROR

# Analysis Configuration
# ----------------------
# Core settings that control the type and scope of analysis
analysis:
  data_type: "longitudinal"       # "single" (one timepoint) or "longitudinal" (multiple timepoints)
  allele_analysis_only: False     # When True, only runs allele analysis and skips scoring/outlier detection

  # Enable/disable specific analysis modules
  # For details on each test and score calculations, see documentation
  use_lmm: True                   # Linear Mixed Models: Best for repeated measures, accounts for subject-level variation
  use_significance_tests: True    # Two-sample (t-test, Mann-Whitney) and single-sample tests: Simple comparisons
  use_cmh: True                   # Cochran-Mantel-Haenszel: Stratified categorical analysis, detects directional changes

  # Timepoints and groups to analyze
  # For longitudinal analysis: specify pairs of timepoints and which one to focus on
  # For single analysis: specify individual timepoints
  timepoints_combinations:
    - timepoint: ["pre", "post"]  # Timepoint pair for longitudinal analysis
      focus: "post"               # FOCUS TIMEPOINT: The derived/later state for evolutionary analysis
                                  # - For dN/dS: focus = derived (Time 2), other = ancestral (Time 1)
                                  # - For CMH scores: measures sites significant at focus but not at other timepoint
                                  # - Guideline: Always choose the LATER or ENDPOINT timepoint as focus
                                  # - Default: If not specified, uses the second timepoint
                                  # - Example: For Day 0 â†’ Day 30, use focus: "day30"
    # - timepoint: ["end"]        # For single timepoint analysis (set data_type: "single")

  groups_combinations:
    - ["treatment", "control"]    # Groups to compare (e.g., treatment vs control)

# Quality Control Parameters
# --------------------------
quality_control:
  min_sample_num: 4               # Minimum samples required for analysis
  breadth_threshold: 0.1          # Minimum coverage breadth (fraction of genome covered)
  coverage_threshold: 1           # Minimum average coverage depth to pass QC
  disable_zero_diff_filtering: False  # Keep sites with zero difference between groups

# Profiling Parameters
# --------------------
# Parameters for pileup generation during sample profiling
profiling:
  ignore_orphans: True           # Ignore orphan reads (without proper pairs)
  min_base_quality: 30            # Minimum base quality score to consider
  min_mapping_quality: 2          # Minimum mapping quality score to consider
  ignore_overlaps: True           # Ignore overlapping read segments

# Statistical Parameters
# ----------------------
statistics:
  filter_type: "t-test"           # Preprocessing filter: "t-test", "wilcoxon", or "both"
  preprocess_between_groups: True # Preprocess data for between-groups tests
  preprocess_within_groups: True  # Preprocess data for within-group tests
  max_zero_count: 4               # Maximum zeros allowed in single-sample test
  p_value_threshold: 0.05         # P-value threshold for significance
  fdr_group_by_mag_id: False      # Apply FDR correction per MAG
  min_positions_after_preprocess: 1  # Minimum positions after preprocessing

# dN/dS Analysis Parameters
# -------------------------
# Configuration for evolutionary rate analysis
dnds:
  p_value_column: "q_value"       # Column for filtering: "min_p_value" or "q_value"
  dn_ds_test_type: "two_sample_paired_tTest"  # Test type for filtering results

# Compute Resources
# -----------------
# Resources allocated per job. Adjust based on your system:
# - Local execution: Use conservative values that fit your workstation
# - Cluster (SLURM): These are passed to sbatch; profile can override
resources:
  threads_per_job: 16             # Threads per job (not total threads)
  mem_per_job: "8G"               # Memory per job. Formats: "8G", "100G", "102400M"
                                  # Local: Keep low to avoid OOM (Snakemake auto-limits jobs)
                                  # Cluster: Can increase; SLURM allocates per-node
  time: "24:00:00"                # Wall time limit (HH:MM:SS)

# Advanced: Per-rule resource overrides (power users only)
# ---------------------------------------------------------
# Uncomment and customize to override resources for specific rules.
# Rule names must match exactly. Unspecified resources use defaults above.
# Most users should NOT need this section.
#
# resources_override:
#   profile:                       # Rule: profile (sample profiling)
#     threads_per_job: 8
#     mem_per_job: "16G"
#     time: "08:00:00"
#   qc:                            # Rule: qc (quality control)
#     mem_per_job: "100G"
#   allele_analysis:               # Rule: allele_analysis
#     mem_per_job: "32G"
#   statistical_tests:             # All statistical test rules:
#                                  # two_sample_unpaired, two_sample_paired, lmm_analysis,
#                                  # cmh_test, single_sample, lmm_analysis_across_time,
#                                  # cmh_test_across_time
#     threads_per_job: 4
#     mem_per_job: "64G"
#     time: "12:00:00"
#   dnds_from_timepoints:          # Rule: dnds_from_timepoints
#     threads_per_job: 1
#     mem_per_job: "200G"
#     time: "48:00:00"
