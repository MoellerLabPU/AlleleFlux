#!/usr/bin/env python3

import os
import sys
import tempfile
import unittest
from io import StringIO
from pathlib import Path
from unittest.mock import MagicMock, Mock, patch

import numpy as np
import pandas as pd

from alleleflux.scripts.preprocessing.quality_control import (
    _aggregate_mag_stats,
    add_subject_count_per_group,
    check_timepoints,
    count_paired_replicates,
    init_worker,
    load_positions_file,
    process_mag_files,
)


class TestQualityControl(unittest.TestCase):

    def setUp(self):
        """Set up test fixtures before each test method."""
        # Sample metadata for testing
        self.metadata_dict = {
            "sample1": {
                "group": "treatment",
                "subjectID": "subject1",
                "replicate": "rep1",
                "time": "T1",
            },
            "sample2": {
                "group": "control",
                "subjectID": "subject1",
                "replicate": "rep1",
                "time": "T2",
            },
            "sample3": {
                "group": "treatment",
                "subjectID": "subject2",
                "replicate": "rep2",
                "time": "T1",
            },
            "sample4": {
                "group": "control",
                "subjectID": "subject2",
                "replicate": "rep2",
                "time": "T2",
            },
        }

        # MAG size dictionary
        self.mag_size_dict = {
            "MAG001": 1000000,  # 1M bp
            "MAG002": 2000000,  # 2M bp
        }

        # Contig length dictionary
        self.contig_length_dict = {
            "contig1": 500000,
            "contig2": 300000,
            "contig3": 200000,
        }

        # Contig to MAG mapping
        self.contig_to_mag = {
            "contig1": "MAG001",
            "contig2": "MAG001",
            "contig3": "MAG002",
        }

        # Initialize worker globals
        init_worker(
            self.metadata_dict,
            self.mag_size_dict,
            self.contig_length_dict,
            self.contig_to_mag,
            positions_filter_map=None,
            positions_denominator="positions",
        )

    def create_temp_profile(self, data):
        """Create a temporary profile file with given data."""
        temp_file = tempfile.NamedTemporaryFile(mode="w", delete=False, suffix=".tsv")
        df = pd.DataFrame(data)
        df.to_csv(temp_file.name, sep="\t", index=False)
        temp_file.close()
        return temp_file.name


class TestProcessMagFiles(TestQualityControl):

    def test_normal_coverage_calculation(self):
        """Test normal coverage calculation with valid data."""
        # Create test profile data
        profile_data = {
            "contig": ["contig1", "contig1", "contig2", "contig2"],
            "position": [1, 2, 1, 2],
            "gene_id": ["gene1", "gene2", "gene3", "gene4"],
            "total_coverage": [10.0, 20.0, 5.0, 15.0],
        }

        profile_file = self.create_temp_profile(profile_data)

        try:
            args = ("sample1", profile_file, "MAG001", 0.1)
            result = process_mag_files(args)

            # Check basic structure
            self.assertEqual(result["sample_id"], "sample1")
            self.assertEqual(result["MAG_ID"], "MAG001")
            self.assertEqual(result["genome_size"], 1000000)

            # Check coverage calculations
            self.assertEqual(
                result["breadth"], 4 / 1000000
            )  # 4 positions with coverage >= 1
            self.assertEqual(
                result["average_coverage"], 50.0 / 1000000
            )  # sum of coverage / genome size
            self.assertEqual(
                result["median_coverage"], 12.5
            )  # median of [10, 20, 5, 15]

            # Check median including zeros
            expected_median_with_zeros = np.median(
                np.concatenate([[10.0, 20.0, 5.0, 15.0], np.zeros(1000000 - 4)])
            )
            self.assertEqual(
                result["median_coverage_including_zeros"], expected_median_with_zeros
            )

            # Should pass breadth threshold (4/1000000 > 0.1 is False, but we can adjust)
            self.assertTrue(
                result["breadth_threshold_passed"] or result["breadth_fail_reason"]
            )

        finally:
            os.unlink(profile_file)

    def test_zero_coverage_warning(self):
        """Test that zero coverage values trigger a warning."""
        profile_data = {
            "contig": ["contig1", "contig1"],
            "position": [1, 2],
            "gene_id": ["gene1", "gene2"],
            "total_coverage": [10.0, 0.0],  # One zero coverage
        }

        profile_file = self.create_temp_profile(profile_data)

        try:
            with patch(
                "alleleflux.scripts.preprocessing.quality_control.logger"
            ) as mock_logger:
                args = ("sample1", profile_file, "MAG001", 0.1)
                result = process_mag_files(args)

                # Check that warning was logged
                mock_logger.warning.assert_called()
                warning_call = mock_logger.warning.call_args[0][0]
                self.assertIn("positions with zero coverage", warning_call)

                # Check that median_coverage excludes zeros
                self.assertEqual(
                    result["median_coverage"], 10.0
                )  # Only the non-zero value

        finally:
            os.unlink(profile_file)

    def test_mag_filtering(self):
        """Test MAG filtering functionality."""
        profile_data = {
            "contig": ["contig1", "contig2", "contig3"],  # contig3 belongs to MAG002
            "position": [1, 1, 1],
            "gene_id": ["gene1", "gene2", "gene3"],
            "total_coverage": [10.0, 20.0, 30.0],
        }

        profile_file = self.create_temp_profile(profile_data)

        try:
            with patch(
                "alleleflux.scripts.preprocessing.quality_control.logger"
            ) as mock_logger:
                args = ("sample1", profile_file, "MAG001", 0.1)  # Processing MAG001
                result = process_mag_files(args)

                # Should warn about filtering out contig3
                mock_logger.warning.assert_called()
                warning_call = mock_logger.warning.call_args[0][0]
                self.assertIn("1 rows not belonging to MAG MAG001", warning_call)

                # Should only include contig1 and contig2 in calculations
                self.assertEqual(result["median_coverage"], 15.0)  # median of [10, 20]

        finally:
            os.unlink(profile_file)

    def test_invalid_mag_size(self):
        """Test handling of invalid MAG sizes."""
        profile_data = {
            "contig": ["contig1"],
            "position": [1],
            "gene_id": ["gene1"],
            "total_coverage": [10.0],
        }

        profile_file = self.create_temp_profile(profile_data)

        try:
            args = ("sample1", profile_file, "INVALID_MAG", 0.1)
            result = process_mag_files(args)

            # Should fail with appropriate error message
            self.assertFalse(result["breadth_threshold_passed"])
            self.assertIn(
                "MAG size for INVALID_MAG not found", result["breadth_fail_reason"]
            )

        finally:
            os.unlink(profile_file)

    def test_length_weighted_coverage(self):
        """Test length-weighted coverage calculation."""
        profile_data = {
            "contig": ["contig1", "contig1", "contig2", "contig2"],
            "position": [1, 2, 1, 2],
            "gene_id": ["gene1", "gene2", "gene3", "gene4"],
            "total_coverage": [
                10.0,
                20.0,
                30.0,
                40.0,
            ],  # contig1: 30 total, contig2: 70 total
        }

        profile_file = self.create_temp_profile(profile_data)

        try:
            args = ("sample1", profile_file, "MAG001", 0.1)
            result = process_mag_files(args)

            # contig1: mean_coverage = 30/500000, contig2: mean_coverage = 70/300000
            # length_weighted = (30/500000 * 500000 + 70/300000 * 300000) / (500000 + 300000)
            # = (30 + 70) / 800000 = 100/800000 = 0.000125
            expected_lw_coverage = (30 + 70) / (500000 + 300000)
            self.assertAlmostEqual(
                result["length_weighted_coverage"], expected_lw_coverage
            )

        finally:
            os.unlink(profile_file)


class TestCheckTimepoints(TestQualityControl):

    def test_single_data_type(self):
        """Test single data type skips timepoint checks."""
        df = pd.DataFrame(
            {
                "subjectID": ["subject1", "subject2"],
                "breadth_threshold_passed": [True, False],
            }
        )

        result = check_timepoints(df, "single")

        # Should match breadth_threshold_passed
        self.assertTrue(result.loc[0, "two_timepoints_passed"])
        self.assertFalse(result.loc[1, "two_timepoints_passed"])

    def test_longitudinal_valid_timepoints(self):
        """Test longitudinal data with valid timepoints."""
        df = pd.DataFrame(
            {
                "subjectID": ["subject1", "subject1", "subject2", "subject2"],
                "time": ["T1", "T2", "T1", "T2"],
                "breadth_threshold_passed": [True, True, True, True],
            }
        )

        result = check_timepoints(df, "longitudinal")

        # All should pass since both subjects have 2 timepoints
        self.assertTrue(all(result["two_timepoints_passed"]))

    def test_longitudinal_missing_timepoint(self):
        """Test longitudinal data with missing timepoints."""
        df = pd.DataFrame(
            {
                "subjectID": [
                    "subject1",
                    "subject1",
                    "subject2",
                ],  # subject2 missing T2
                "time": ["T1", "T2", "T1"],
                "breadth_threshold_passed": [True, True, True],
            }
        )

        result = check_timepoints(df, "longitudinal")

        # Only subject1 should pass (has both timepoints)
        subject1_mask = result["subjectID"] == "subject1"
        subject2_mask = result["subjectID"] == "subject2"

        self.assertTrue(all(result.loc[subject1_mask, "two_timepoints_passed"]))
        self.assertFalse(any(result.loc[subject2_mask, "two_timepoints_passed"]))

    def test_too_many_timepoints(self):
        """Test error when more than 2 timepoints found."""
        df = pd.DataFrame(
            {
                "subjectID": ["subject1", "subject1", "subject1"],
                "time": ["T1", "T2", "T3"],  # 3 timepoints
                "breadth_threshold_passed": [True, True, True],
            }
        )

        with self.assertRaises(ValueError) as context:
            check_timepoints(df, "longitudinal")

        self.assertIn("More than 2 unique timepoints", str(context.exception))


class TestSubjectCounting(TestQualityControl):

    def test_add_subject_count_per_group(self):
        """Test subject and replicate counting per group."""
        df = pd.DataFrame(
            {
                "two_timepoints_passed": [True, True, True, False],
                "group": ["treatment", "treatment", "control", "control"],
                "subjectID": ["subject1", "subject2", "subject1", "subject3"],
                "replicate": ["rep1", "rep2", "rep1", "rep3"],
            }
        )

        result = add_subject_count_per_group(df)

        # Treatment group: 2 subjects, 2 replicates
        treatment_mask = (result["group"] == "treatment") & result[
            "two_timepoints_passed"
        ]
        self.assertTrue(all(result.loc[treatment_mask, "subjects_per_group"] == 2))
        self.assertTrue(all(result.loc[treatment_mask, "replicates_per_group"] == 2))

        # Control group: 1 subject, 1 replicate (subject3 failed timepoints)
        control_mask = (result["group"] == "control") & result["two_timepoints_passed"]
        self.assertTrue(all(result.loc[control_mask, "subjects_per_group"] == 1))
        self.assertTrue(all(result.loc[control_mask, "replicates_per_group"] == 1))

        # Failed samples should have NaN
        failed_mask = ~result["two_timepoints_passed"]
        self.assertTrue(all(result.loc[failed_mask, "subjects_per_group"].isna()))

    def test_count_paired_replicates(self):
        """Test paired replicate counting."""
        df = pd.DataFrame(
            {
                "two_timepoints_passed": [True, True, True, True, True],
                "group": ["treatment", "control", "treatment", "control", "treatment"],
                "replicate": [
                    "rep1",
                    "rep1",
                    "rep2",
                    "rep2",
                    "rep3",
                ],  # rep1 and rep2 are paired
            }
        )

        result = count_paired_replicates(df)

        # rep1 and rep2 appear in both groups, so 2 paired replicates per group
        paired_mask = result["replicate"].isin(["rep1", "rep2"])
        self.assertTrue(
            all(result.loc[paired_mask, "paired_replicates_per_group"] == 2)
        )

        # rep3 only in treatment, should be NaN
        unpaired_mask = result["replicate"] == "rep3"
        self.assertTrue(
            all(result.loc[unpaired_mask, "paired_replicates_per_group"].isna())
        )


class TestAggregation(TestQualityControl):

    def test_aggregate_mag_stats_group(self):
        """Test MAG statistics aggregation by group."""
        df_results = pd.DataFrame(
            {
                "sample_id": [
                    "sample1",
                    "sample2",
                    "sample3",
                    "sample4",
                ],  # Add missing column
                "breadth_threshold_passed": [True, True, True, True],
                "group": ["treatment", "treatment", "control", "control"],
                "breadth": [0.8, 0.9, 0.7, 0.6],
                "average_coverage": [50.0, 60.0, 40.0, 30.0],
                "median_coverage": [45.0, 55.0, 35.0, 25.0],
                "median_coverage_including_zeros": [0.1, 0.2, 0.05, 0.03],
                "coverage_std": [15.0, 20.0, 12.0, 8.0],
                "coverage_std_including_zeros": [25.0, 30.0, 20.0, 15.0],
                "length_weighted_coverage": [48.0, 58.0, 38.0, 28.0],
                "subjects_per_group": [2, 2, 2, 2],
                "replicates_per_group": [2, 2, 2, 2],
                "paired_replicates_per_group": [1, 1, 1, 1],
            }
        )

        result = _aggregate_mag_stats(df_results, "MAG001", ["group"], overall=False)

        # Should have 2 rows (treatment and control)
        self.assertEqual(len(result), 2)
        self.assertIn("MAG_ID", result.columns)
        self.assertTrue(all(result["MAG_ID"] == "MAG001"))

        # Check treatment group means (now with _mean suffix)
        treatment_row = result[result["group"] == "treatment"].iloc[0]
        self.assertAlmostEqual(treatment_row["breadth_mean"], 0.85)  # (0.8 + 0.9) / 2
        self.assertAlmostEqual(
            treatment_row["average_coverage_mean"], 55.0
        )  # (50 + 60) / 2

    def test_aggregate_excludes_breadth_genome(self):
        """Test that breadth_genome is NOT included in aggregated statistics."""
        # Create sample data with breadth_genome field (dual breadth mode)
        df_results = pd.DataFrame(
            {
                "sample_id": ["sample1", "sample2"],
                "breadth_threshold_passed": [True, True],
                "group": ["treatment", "treatment"],
                "breadth": [0.8, 0.9],
                "breadth_genome": [
                    0.0001,
                    0.0002,
                ],  # Should be excluded from aggregation
                "average_coverage": [50.0, 60.0],
                "median_coverage": [45.0, 55.0],
                "median_coverage_including_zeros": [0.1, 0.2],
                "coverage_std": [15.0, 20.0],
                "coverage_std_including_zeros": [25.0, 30.0],
                "subjects_per_group": [2, 2],
                "replicates_per_group": [2, 2],
                "paired_replicates_per_group": [1, 1],
            }
        )

        # Test group aggregation
        result = _aggregate_mag_stats(df_results, "MAG001", ["group"], overall=False)

        # breadth_genome should NOT be in the aggregated results
        self.assertNotIn("breadth_genome", result.columns)
        self.assertNotIn("breadth_genome_mean", result.columns)

        # But breadth should be aggregated
        self.assertIn("breadth_mean", result.columns)

        # Test overall aggregation
        result_overall = _aggregate_mag_stats(df_results, "MAG001", [], overall=True)

        # breadth_genome should NOT be in overall results either
        self.assertNotIn("breadth_genome", result_overall.columns)
        self.assertNotIn("breadth_genome_mean", result_overall.columns)

        # But breadth should be aggregated
        self.assertIn("breadth_mean", result_overall.columns)

    def test_aggregate_mag_stats_overall(self):
        """Test overall MAG statistics aggregation."""
        df_results = pd.DataFrame(
            {
                "sample_id": ["sample1", "sample2"],  # Add missing column
                "breadth_threshold_passed": [True, True],
                "breadth": [0.8, 0.6],
                "average_coverage": [50.0, 30.0],
                "median_coverage": [45.0, 25.0],
                "median_coverage_including_zeros": [0.1, 0.03],
                "coverage_std": [15.0, 8.0],
                "coverage_std_including_zeros": [25.0, 15.0],
                "length_weighted_coverage": [48.0, 28.0],
                "subjects_per_group": [2, 2],
                "replicates_per_group": [2, 2],
                "paired_replicates_per_group": [1, 1],
            }
        )

        result = _aggregate_mag_stats(df_results, "MAG001", [], overall=True)

        # Should have 1 row with _mean suffix columns
        self.assertEqual(len(result), 1)
        self.assertEqual(result.iloc[0]["MAG_ID"], "MAG001")
        self.assertEqual(result.iloc[0]["num_samples"], 2)
        self.assertAlmostEqual(result.iloc[0]["breadth_mean"], 0.7)  # (0.8 + 0.6) / 2
        self.assertAlmostEqual(
            result.iloc[0]["average_coverage_mean"], 40.0
        )  # (50 + 30) / 2

    def test_aggregate_empty_results(self):
        """Test aggregation with empty results."""
        df_results = pd.DataFrame()

        result = _aggregate_mag_stats(df_results, "MAG001", ["group"], overall=False)

        # Should return None for empty input
        self.assertIsNone(result)


class TestPositionsFiltering(TestQualityControl):
    """Test the new positions filtering functionality."""

    def test_positions_considered_field(self):
        """positions_considered only exists when positions filter is used."""
        # Scenario 1: No positions filter - positions_considered should be absent
        profile_data = {
            "contig": ["contig1", "contig1"],
            "position": [1, 2],
            "gene_id": ["gene1", "gene2"],
            "total_coverage": [10.0, 20.0],
        }

        profile_file = self.create_temp_profile(profile_data)

        try:
            # No positions filter
            init_worker(
                self.metadata_dict,
                self.mag_size_dict,
                self.contig_length_dict,
                self.contig_to_mag,
                positions_filter_map=None,
                positions_denominator="positions",
            )

            args = ("sample1", profile_file, "MAG001", 0.1)
            result = process_mag_files(args)

            # positions_considered should not be present when no filter is provided
            self.assertNotIn("positions_considered", result)
            # breadth_genome should also not be present without positions filter
            self.assertNotIn("breadth_genome", result)

        finally:
            os.unlink(profile_file)

    def test_positions_filter_with_set(self):
        """Test filtering with positions set (new implementation)."""
        # Create test profile data
        profile_data = {
            "contig": ["contig1", "contig1", "contig1", "contig2"],
            "position": [1, 2, 3, 1],
            "gene_id": ["gene1", "gene2", "gene3", "gene4"],
            "total_coverage": [10.0, 20.0, 30.0, 40.0],
        }

        profile_file = self.create_temp_profile(profile_data)

        try:
            # Create positions filter as a set of tuples (new format)
            positions_filter = {
                "MAG001": {("contig1", 1), ("contig1", 2)}  # Only first 2 positions
            }

            # Re-initialize worker with positions filter
            init_worker(
                self.metadata_dict,
                self.mag_size_dict,
                self.contig_length_dict,
                self.contig_to_mag,
                positions_filter_map=positions_filter,
                positions_denominator="positions",
            )

            args = ("sample1", profile_file, "MAG001", 0.0001)
            result = process_mag_files(args)

            # Should only include 2 positions (contig1:1 and contig1:2)
            self.assertEqual(result["positions_considered"], 2)
            # Average coverage: (10 + 20) / 2 = 15 (denominator is positions count)
            self.assertAlmostEqual(result["average_coverage"], 15.0)
            # Breadth: 2 positions with coverage / 2 total positions = 1.0
            self.assertAlmostEqual(result["breadth"], 1.0)
            # Median coverage: median of [10, 20] = 15
            self.assertAlmostEqual(result["median_coverage"], 15.0)
            # In dual breadth mode (positions + positions_denominator="positions"),
            # breadth_threshold_passed should exist and breadth_genome should be calculated
            self.assertIn("breadth_threshold_passed", result)
            self.assertIn("breadth_genome", result)
            # breadth_genome should be 4/1000000 (all 4 positions in profile had coverage)
            self.assertAlmostEqual(result["breadth_genome"], 4 / 1000000)

        finally:
            os.unlink(profile_file)
            # Reset worker to default state
            init_worker(
                self.metadata_dict,
                self.mag_size_dict,
                self.contig_length_dict,
                self.contig_to_mag,
                positions_filter_map=None,
                positions_denominator="positions",
            )

    def test_positions_filter_genome_denominator(self):
        """Test filtering with genome denominator mode."""
        profile_data = {
            "contig": ["contig1", "contig1"],
            "position": [1, 2],
            "gene_id": ["gene1", "gene2"],
            "total_coverage": [10.0, 20.0],
        }

        profile_file = self.create_temp_profile(profile_data)

        try:
            # Create positions filter
            positions_filter = {"MAG001": {("contig1", 1), ("contig1", 2)}}

            # Initialize with genome denominator mode
            init_worker(
                self.metadata_dict,
                self.mag_size_dict,
                self.contig_length_dict,
                self.contig_to_mag,
                positions_filter_map=positions_filter,
                positions_denominator="genome",  # Use genome size as denominator
            )

            args = ("sample1", profile_file, "MAG001", 0.0001)
            result = process_mag_files(args)

            # positions_considered should still be recorded
            self.assertEqual(result["positions_considered"], 2)
            # Average coverage: (10 + 20) / 1000000 (genome size) = 0.00003
            self.assertAlmostEqual(result["average_coverage"], 30.0 / 1000000)
            # Breadth: 2 positions / 1000000 = 0.000002
            self.assertAlmostEqual(result["breadth"], 2.0 / 1000000)
            # Breadth threshold fields should not exist when positions filter is active
            self.assertNotIn("breadth_threshold_passed", result)
            self.assertNotIn("breadth_fail_reason", result)

        finally:
            os.unlink(profile_file)
            # Reset worker
            init_worker(
                self.metadata_dict,
                self.mag_size_dict,
                self.contig_length_dict,
                self.contig_to_mag,
                positions_filter_map=None,
                positions_denominator="positions",
            )

    def test_positions_filter_no_matches(self):
        """Test positions filter when no positions match."""
        profile_data = {
            "contig": ["contig1"],
            "position": [100],  # Position not in filter
            "gene_id": ["gene1"],
            "total_coverage": [10.0],
        }

        profile_file = self.create_temp_profile(profile_data)

        try:
            # Create positions filter with different positions
            positions_filter = {"MAG001": {("contig1", 1), ("contig1", 2)}}

            init_worker(
                self.metadata_dict,
                self.mag_size_dict,
                self.contig_length_dict,
                self.contig_to_mag,
                positions_filter_map=positions_filter,
                positions_denominator="genome",
            )

            args = ("sample1", profile_file, "MAG001", 0.1)
            result = process_mag_files(args)

            # Should return early with empty df - breadth fields don't exist
            self.assertNotIn("breadth_threshold_passed", result)
            self.assertNotIn("breadth_fail_reason", result)
            self.assertEqual(result["positions_considered"], 2)

        finally:
            os.unlink(profile_file)
            # Reset worker
            init_worker(
                self.metadata_dict,
                self.mag_size_dict,
                self.contig_length_dict,
                self.contig_to_mag,
                positions_filter_map=None,
                positions_denominator="positions",
            )

    def test_positions_filter_skips_length_weighted_coverage(self):
        """Test that length-weighted coverage is absent when positions filter is active."""
        profile_data = {
            "contig": ["contig1", "contig1"],
            "position": [1, 2],
            "gene_id": ["gene1", "gene2"],
            "total_coverage": [10.0, 20.0],
        }

        profile_file = self.create_temp_profile(profile_data)

        try:
            positions_filter = {"MAG001": {("contig1", 1), ("contig1", 2)}}

            init_worker(
                self.metadata_dict,
                self.mag_size_dict,
                self.contig_length_dict,
                self.contig_to_mag,
                positions_filter_map=positions_filter,
                positions_denominator="positions",
            )

            args = ("sample1", profile_file, "MAG001", 0.0001)
            result = process_mag_files(args)

            # Length-weighted coverage should not exist when positions filter is active
            self.assertNotIn("length_weighted_coverage", result)

        finally:
            os.unlink(profile_file)
            # Reset worker
            init_worker(
                self.metadata_dict,
                self.mag_size_dict,
                self.contig_length_dict,
                self.contig_to_mag,
                positions_filter_map=None,
                positions_denominator="positions",
            )

    def test_dual_breadth_mode_basic(self):
        """Test dual breadth mode: positions file + positions_denominator='positions'."""
        # Create profile with 4 positions total, but filter to only 2
        profile_data = {
            "contig": ["contig1", "contig1", "contig1", "contig1"],
            "position": [1, 2, 3, 4],
            "gene_id": ["gene1", "gene2", "gene3", "gene4"],
            "total_coverage": [10.0, 20.0, 30.0, 40.0],  # All have coverage
        }

        profile_file = self.create_temp_profile(profile_data)

        try:
            # Filter to only positions 1 and 2
            positions_filter = {"MAG001": {("contig1", 1), ("contig1", 2)}}

            init_worker(
                self.metadata_dict,
                self.mag_size_dict,
                self.contig_length_dict,
                self.contig_to_mag,
                positions_filter_map=positions_filter,
                positions_denominator="positions",  # Dual breadth mode
            )

            args = ("sample1", profile_file, "MAG001", 0.000001)  # Low threshold
            result = process_mag_files(args)

            # Verify breadth_genome exists and is calculated from all 4 positions
            self.assertIn("breadth_genome", result)
            # All 4 positions have coverage, genome size is 1M
            expected_breadth_genome = 4 / 1000000
            self.assertAlmostEqual(result["breadth_genome"], expected_breadth_genome)

            # Verify breadth is calculated from filtered positions (2 out of 2)
            self.assertEqual(result["breadth"], 1.0)

            # Verify breadth_threshold_passed exists in dual breadth mode
            self.assertIn("breadth_threshold_passed", result)
            # Should pass because breadth_genome (4/1M) > threshold
            self.assertTrue(result["breadth_threshold_passed"])

            # Verify positions_considered is present
            self.assertEqual(result["positions_considered"], 2)

        finally:
            os.unlink(profile_file)
            # Reset worker
            init_worker(
                self.metadata_dict,
                self.mag_size_dict,
                self.contig_length_dict,
                self.contig_to_mag,
                positions_filter_map=None,
                positions_denominator="positions",
            )

    def test_dual_breadth_mode_threshold_check(self):
        """Test that breadth_threshold_passed uses breadth_genome in dual breadth mode."""
        # Profile with 100 positions total, only 10 in filter
        profile_data = {
            "contig": ["contig1"] * 100,
            "position": list(range(1, 101)),
            "gene_id": [f"gene{i}" for i in range(1, 101)],
            "total_coverage": [10.0] * 100,  # All covered
        }

        profile_file = self.create_temp_profile(profile_data)

        try:
            # Filter to only first 10 positions
            positions_filter = {"MAG001": {("contig1", i) for i in range(1, 11)}}

            init_worker(
                self.metadata_dict,
                self.mag_size_dict,
                self.contig_length_dict,
                self.contig_to_mag,
                positions_filter_map=positions_filter,
                positions_denominator="positions",
            )

            # Set threshold that breadth_genome passes but breadth wouldn't if checked
            # breadth_genome = 100/1M = 0.0001
            # breadth (filtered) = 10/10 = 1.0
            # Set threshold at 0.00005 (breadth_genome should pass)
            args = ("sample1", profile_file, "MAG001", 0.00005)
            result = process_mag_files(args)

            # Verify breadth_genome passes
            self.assertAlmostEqual(result["breadth_genome"], 100 / 1000000)
            self.assertTrue(result["breadth_threshold_passed"])
            self.assertEqual(result["breadth_fail_reason"], "")

            # Now test with threshold that breadth_genome fails
            args = ("sample1", profile_file, "MAG001", 0.0002)  # Higher threshold
            result = process_mag_files(args)

            self.assertFalse(result["breadth_threshold_passed"])
            self.assertIn("Breadth (genome)", result["breadth_fail_reason"])
            self.assertIn("threshold", result["breadth_fail_reason"])

        finally:
            os.unlink(profile_file)
            # Reset worker
            init_worker(
                self.metadata_dict,
                self.mag_size_dict,
                self.contig_length_dict,
                self.contig_to_mag,
                positions_filter_map=None,
                positions_denominator="positions",
            )

    def test_dual_breadth_mode_partial_coverage(self):
        """Test dual breadth with partial coverage (some positions lack coverage)."""
        # Profile with positions that have varying coverage including some zeros
        profile_data = {
            "contig": ["contig1"] * 10,
            "position": list(range(1, 11)),
            "gene_id": [f"gene{i}" for i in range(1, 11)],
            "total_coverage": [10.0, 0.0, 20.0, 0.0, 30.0, 0.0, 40.0, 0.0, 50.0, 0.0],
        }

        profile_file = self.create_temp_profile(profile_data)

        try:
            # Filter to all 10 positions
            positions_filter = {"MAG001": {("contig1", i) for i in range(1, 11)}}

            init_worker(
                self.metadata_dict,
                self.mag_size_dict,
                self.contig_length_dict,
                self.contig_to_mag,
                positions_filter_map=positions_filter,
                positions_denominator="positions",
            )

            args = ("sample1", profile_file, "MAG001", 0.1)
            result = process_mag_files(args)

            # breadth_genome: 5 positions with coverage >= 1 out of 1M genome
            expected_breadth_genome = 5 / 1000000
            self.assertAlmostEqual(result["breadth_genome"], expected_breadth_genome)

            # breadth: 5 positions with coverage >= 1 out of 10 filtered positions
            expected_breadth = 5 / 10
            self.assertAlmostEqual(result["breadth"], expected_breadth)

        finally:
            os.unlink(profile_file)
            # Reset worker
            init_worker(
                self.metadata_dict,
                self.mag_size_dict,
                self.contig_length_dict,
                self.contig_to_mag,
                positions_filter_map=None,
                positions_denominator="positions",
            )

    def test_positions_genome_denominator_no_dual_breadth(self):
        """Test that positions_denominator='genome' does NOT create dual breadth."""
        profile_data = {
            "contig": ["contig1", "contig1"],
            "position": [1, 2],
            "gene_id": ["gene1", "gene2"],
            "total_coverage": [10.0, 20.0],
        }

        profile_file = self.create_temp_profile(profile_data)

        try:
            positions_filter = {"MAG001": {("contig1", 1), ("contig1", 2)}}

            # Use genome denominator mode (not dual breadth)
            init_worker(
                self.metadata_dict,
                self.mag_size_dict,
                self.contig_length_dict,
                self.contig_to_mag,
                positions_filter_map=positions_filter,
                positions_denominator="genome",  # Uses genome, not dual breadth
            )

            args = ("sample1", profile_file, "MAG001", 0.0001)
            result = process_mag_files(args)

            # breadth_genome should NOT exist with genome denominator
            self.assertNotIn("breadth_genome", result)

            # breadth_threshold_passed should NOT exist in genome denominator mode with filter
            self.assertNotIn("breadth_threshold_passed", result)
            self.assertNotIn("breadth_fail_reason", result)

            # But positions_considered should still exist
            self.assertEqual(result["positions_considered"], 2)

        finally:
            os.unlink(profile_file)
            # Reset worker
            init_worker(
                self.metadata_dict,
                self.mag_size_dict,
                self.contig_length_dict,
                self.contig_to_mag,
                positions_filter_map=None,
                positions_denominator="positions",
            )

    def test_no_positions_file_no_dual_breadth(self):
        """Test that without positions file, no dual breadth fields are created."""
        profile_data = {
            "contig": ["contig1", "contig1"],
            "position": [1, 2],
            "gene_id": ["gene1", "gene2"],
            "total_coverage": [10.0, 20.0],
        }

        profile_file = self.create_temp_profile(profile_data)

        try:
            # No positions filter
            init_worker(
                self.metadata_dict,
                self.mag_size_dict,
                self.contig_length_dict,
                self.contig_to_mag,
                positions_filter_map=None,
                positions_denominator="positions",  # Doesn't matter without filter
            )

            args = ("sample1", profile_file, "MAG001", 0.1)
            result = process_mag_files(args)

            # breadth_genome should NOT exist without positions filter
            self.assertNotIn("breadth_genome", result)

            # Standard breadth_threshold_passed should exist
            self.assertIn("breadth_threshold_passed", result)

            # positions_considered should NOT exist
            self.assertNotIn("positions_considered", result)

        finally:
            os.unlink(profile_file)


class TestPathHandling(unittest.TestCase):
    """Test Path object handling in quality_control."""

    def test_load_positions_file_with_path_object(self):
        """Test that load_positions_file accepts Path objects."""
        with tempfile.NamedTemporaryFile(mode="w", suffix=".tsv", delete=False) as f:
            f.write("MAG\tcontig\tposition\n")
            f.write("MAG001\tcontig1\t1\n")
            f.write("MAG001\tcontig1\t2\n")
            f.write("MAG002\tcontig2\t5\n")
            temp_path = Path(f.name)

        try:
            # Should accept Path object
            positions_map = load_positions_file(temp_path)

            self.assertIsInstance(positions_map, dict)
            self.assertIn("MAG001", positions_map)
            self.assertIn("MAG002", positions_map)
            # Verify set-based storage
            self.assertIsInstance(positions_map["MAG001"], set)
            self.assertIn(("contig1", 1), positions_map["MAG001"])
            self.assertIn(("contig1", 2), positions_map["MAG001"])
            self.assertIn(("contig2", 5), positions_map["MAG002"])

        finally:
            temp_path.unlink()

    def test_load_positions_file_with_string_path(self):
        """Test that load_positions_file still accepts string paths."""
        with tempfile.NamedTemporaryFile(mode="w", suffix=".tsv", delete=False) as f:
            f.write("MAG\tcontig\tposition\n")
            f.write("MAG001\tcontig1\t1\n")
            temp_str_path = f.name

        try:
            # Should accept string path (converted internally)
            positions_map = load_positions_file(temp_str_path)
            self.assertIn("MAG001", positions_map)

        finally:
            Path(temp_str_path).unlink()


class TestEdgeCases(TestQualityControl):

    def test_empty_profile_after_filtering(self):
        """Test handling when profile is empty after MAG filtering."""
        profile_data = {
            "contig": ["contig3"],  # Only contig3, which belongs to MAG002
            "position": [1],
            "gene_id": ["gene1"],
            "total_coverage": [10.0],
        }

        profile_file = self.create_temp_profile(profile_data)

        try:
            args = ("sample1", profile_file, "MAG001", 0.1)  # Processing MAG001
            result = process_mag_files(args)

            # Should fail because no rows remain after filtering
            self.assertFalse(result["breadth_threshold_passed"])
            self.assertIn(
                "No rows remain after filtering", result["breadth_fail_reason"]
            )

        finally:
            os.unlink(profile_file)

    def test_all_zero_coverage(self):
        """Test profile with all zero coverage values."""
        profile_data = {
            "contig": ["contig1", "contig1"],
            "position": [1, 2],
            "gene_id": ["gene1", "gene2"],
            "total_coverage": [0.0, 0.0],
        }

        profile_file = self.create_temp_profile(profile_data)

        try:
            args = ("sample1", profile_file, "MAG001", 0.1)
            result = process_mag_files(args)

            # median_coverage should be NaN (no positive coverage)
            self.assertTrue(np.isnan(result["median_coverage"]))
            self.assertTrue(np.isnan(result["coverage_std"]))

            # But median_coverage_including_zeros should be 0.0
            self.assertEqual(result["median_coverage_including_zeros"], 0.0)

        finally:
            os.unlink(profile_file)

    def test_no_valid_subjects(self):
        """Test subject counting with no valid subjects."""
        df = pd.DataFrame(
            {
                "two_timepoints_passed": [False, False],
                "group": ["treatment", "control"],
                "subjectID": ["subject1", "subject2"],
                "replicate": ["rep1", "rep2"],
            }
        )

        result = add_subject_count_per_group(df)

        # All should be NaN since no subjects passed
        self.assertTrue(all(result["subjects_per_group"].isna()))
        self.assertTrue(all(result["replicates_per_group"].isna()))

    def test_single_data_type_aggregation(self):
        """Test that aggregation works correctly when data_type='single'."""
        # Create sample data without 'time' column (single timepoint)
        df_results = pd.DataFrame(
            {
                "sample_id": ["sample1", "sample2", "sample3"],
                "breadth_threshold_passed": [True, True, True],
                "group": ["treatment", "treatment", "control"],
                "breadth": [0.8, 0.9, 0.7],
                "average_coverage": [50.0, 60.0, 40.0],
                "median_coverage": [45.0, 55.0, 35.0],
                "median_coverage_including_zeros": [0.1, 0.2, 0.05],
                "coverage_std": [15.0, 20.0, 12.0],
                "coverage_std_including_zeros": [25.0, 30.0, 20.0],
                "length_weighted_coverage": [48.0, 58.0, 38.0],
                "subjects_per_group": [1, 1, 1],
                "replicates_per_group": [1, 1, 1],
                "paired_replicates_per_group": [1, 1, 1],
                # Note: NO 'time' column for single data type
            }
        )

        # Test group summary (should work, now with _mean suffix)
        group_summary = _aggregate_mag_stats(
            df_results, "MAG001", ["group"], overall=False
        )
        self.assertIsNotNone(group_summary)
        self.assertEqual(len(group_summary), 2)  # treatment and control
        # Verify _mean suffix is added to metric columns
        self.assertIn("breadth_mean", group_summary.columns)
        self.assertIn("average_coverage_mean", group_summary.columns)

        # Test overall summary (should work)
        overall_summary = _aggregate_mag_stats(df_results, "MAG001", [], overall=True)
        self.assertIsNotNone(overall_summary)
        self.assertEqual(len(overall_summary), 1)

        # Test group-time summary (should return None since no 'time' column)
        # This simulates the check: if "time" in df_results.columns
        if "time" in df_results.columns:
            group_time_summary = _aggregate_mag_stats(
                df_results, "MAG001", ["group", "time"], overall=False
            )
        else:
            group_time_summary = None

        self.assertIsNone(group_time_summary)  # Should be None for single data type

    def test_single_data_type_end_to_end(self):
        """Test complete flow with single data type from check_timepoints to aggregation."""
        # Start with data that simulates single data type processing
        df_results = pd.DataFrame(
            {
                "sample_id": ["sample1", "sample2"],
                "subjectID": ["subject1", "subject2"],
                "group": ["treatment", "control"],
                "replicate": ["rep1", "rep2"],
                "breadth_threshold_passed": [True, True],
                "breadth": [0.8, 0.7],
                "average_coverage": [50.0, 40.0],
                "median_coverage": [45.0, 35.0],
                "median_coverage_including_zeros": [0.1, 0.05],
                "coverage_std": [15.0, 12.0],
                "coverage_std_including_zeros": [25.0, 20.0],
                "length_weighted_coverage": [48.0, 38.0],
                # Note: NO 'time' column for single data type
            }
        )

        # Process through check_timepoints with data_type='single'
        df_after_timepoints = check_timepoints(df_results, "single")

        # Should have two_timepoints_passed matching breadth_threshold_passed
        self.assertTrue(
            all(
                df_after_timepoints["two_timepoints_passed"]
                == df_after_timepoints["breadth_threshold_passed"]
            )
        )

        # Process through subject counting
        df_with_counts = add_subject_count_per_group(df_after_timepoints)

        # Process through replicate counting
        df_final = count_paired_replicates(df_with_counts)

        # Test aggregation (simulating the logic in process_mag)
        group_summary = _aggregate_mag_stats(
            df_final, "MAG001", ["group"], overall=False
        )
        overall_summary = _aggregate_mag_stats(df_final, "MAG001", [], overall=True)

        # Group-time summary should be None (no time column)
        group_time_summary = None
        if "time" in df_final.columns:
            group_time_summary = _aggregate_mag_stats(
                df_final, "MAG001", ["group", "time"], overall=False
            )

        # Verify results
        self.assertIsNotNone(group_summary)
        self.assertIsNotNone(overall_summary)
        self.assertIsNone(group_time_summary)  # Should be None for single data type

        # Verify group summary structure (now with _mean suffix)
        self.assertEqual(len(group_summary), 2)  # treatment and control
        self.assertTrue(all(group_summary["MAG_ID"] == "MAG001"))
        self.assertIn("breadth_mean", group_summary.columns)
        self.assertIn("average_coverage_mean", group_summary.columns)

        # Verify overall summary structure (already has _mean suffix)
        self.assertEqual(len(overall_summary), 1)
        self.assertEqual(overall_summary.iloc[0]["MAG_ID"], "MAG001")


if __name__ == "__main__":
    # Create a test suite
    suite = unittest.TestLoader().loadTestsFromModule(sys.modules[__name__])

    # Run the tests
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)

    # Print summary
    print(f"\nTests run: {result.testsRun}")
    print(f"Failures: {len(result.failures)}")
    print(f"Errors: {len(result.errors)}")

    if result.failures:
        print("\nFailures:")
        for test, traceback in result.failures:
            print(f"  {test}: {traceback}")

    if result.errors:
        print("\nErrors:")
        for test, traceback in result.errors:
            print(f"  {test}: {traceback}")
