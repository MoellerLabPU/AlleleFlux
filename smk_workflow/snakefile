import os
import pandas as pd
from glob import glob
from collections import defaultdict


# Load the configuration file
configfile: "config.yml"


OUTDIR = config["root_out"]
# Automatically detect sample IDs based on filenames in the directory
samples = [
    os.path.basename(bam).split(".")[0]
    for bam in glob(os.path.join(config["bamDir"], "*.sorted.bam"))
]


timepoints_labels = [
    "{}_{}".format(*tp) for tp in config["timepoints_combinations"]
]  # ["T1_T2", "T2_T3"]
groups_labels = [
    "{}_{}".format(*gr) for gr in config["groups_combinations"]
]  # ["G1_G2", "G2_G4"]


wildcard_constraints:
    groups="[a-zA-Z0-9_.-]+",
    timepoints="[a-zA-Z0-9_.-]+",


# Define a function to extract MAGs from the checkpoint output
def discovered_mags():
    cp = checkpoints.find_mags.get()  # This ensures the checkpoint is run first
    with open(cp.output[0]) as f:
        results = []
        for line in f:
            tp, gr, mag_list_str = line.strip().split("\t")
            for mag in mag_list_str.split(","):
                results.append((tp, gr, mag))
        return results


rule all:
    input:
        expand(os.path.join(OUTDIR, "profiles", "{sample}.sorted"), sample=samples),
        # Step 2 outputs (directories from generate_metadata)
        expand(
            os.path.join(
                OUTDIR, "inputMetadata", "inputMetadata_{timepoints}-{groups}"
            ),
            timepoints=timepoints_labels,
            groups=groups_labels,
        ),
        lambda wildcards: [
            os.path.join(
                OUTDIR,
                "significanceAnalysis",
                f"significanceAnalysis_{tp}-{gp}",
                f"{mag}_single_sample_test.tsv.gz",
            )
            for tp, gp, mag in discovered_mags()
        ],


#####################################
# Step 1: Profile Samples
#####################################


rule profile:
    input:
        bam=os.path.join(config["bamDir"], "{sample}.sorted.bam"),
        fasta=config["fasta"],
        prodigal=config["prodigal"],
    output:
        directory(os.path.join(OUTDIR, "profiles", "{sample}.sorted")),
    threads: config["cpus"]["profile"]
    log:
        os.path.join(config["logDir"], "profile", "{sample}_profile.log"),
    params:
        outDir=OUTDIR,
        scriptPath=config["scripts"]["profile"],
    shell:
        """
        python {params.scriptPath} \
        --bam_path {input.bam} --fasta_path {input.fasta} --prodigal_fasta {input.prodigal} \
        --cpus {threads} --output_dir {params.outDir} > {log} 2>&1
        """


#####################################
# Step 2: Generate MAG Metadata
#####################################


rule generate_metadata:
    input:
        rootDir=os.path.join(OUTDIR, "profiles"),
        metadata=config["metadata_file"],
    output:
        outDir=directory(
            os.path.join(
                OUTDIR, "inputMetadata", "inputMetadata_{timepoints}-{groups}"
            )
        ),
    params:
        scriptPath=config["scripts"]["generate_mag_metadata"],
    log:
        os.path.join(config["logDir"], "generate_metadata", "{timepoints}-{groups}.log"),
    shell:
        """
        # Extract the two timepoints and groups from the wildcard strings
        TP1=$(echo {wildcards.timepoints} | cut -d'_' -f1)
        TP2=$(echo {wildcards.timepoints} | cut -d'_' -f2)
        G1=$(echo {wildcards.groups} | cut -d'_' -f1)
        G2=$(echo {wildcards.groups} | cut -d'_' -f2)

        python {params.scriptPath} \
            --rootDir {input.rootDir} \
            --metadata {input.metadata} \
            --outDir {output.outDir} \
            --timepoints $TP1 $TP2 \
            --groups $G1 $G2 \
            > {log} 2>&1
         
        """


checkpoint find_mags:
    input:
        # This ensures that the checkpoint will only run when all the below directories exist.
        expand(
            os.path.join(
                OUTDIR, "inputMetadata", "inputMetadata_{timepoints}-{groups}"
            ),
            timepoints=timepoints_labels,
            groups=groups_labels,
        ),
    output:
        os.path.join(OUTDIR, "found_mags.tsv"),
    run:
        # Discover all sample files
        mag_files = glob_wildcards(
            os.path.join(
                OUTDIR,
                "inputMetadata",
                "inputMetadata_{timepoints}-{groups}",
                "{mag}_samples.tsv",
            )
        )
        # mag_files now holds lists of matched wildcards: mag_files.timepoints, mag_files.groups, mag_files.mag

        # Organize the found MAGs by combination of timepoints and groups
        combos = defaultdict(list)
        for tp, gr, mg in zip(mag_files.timepoints, mag_files.groups, mag_files.mag):
            combos[(tp, gr)].append(mg)
            # Write them to a file
        with open(output[0], "w") as f:
            for (tp, gr), mg_list in combos.items():
                f.write(f"{tp}\t{gr}\t{','.join(mg_list)}\n")


#####################################
# Step 3: Process MAGs
#####################################


rule significance_analysis_per_mag:
    input:
        mag_metadata_file=os.path.join(
            OUTDIR,
            "inputMetadata",
            "inputMetadata_{timepoints}-{groups}",
            "{mag}_samples.tsv",
        ),
    output:
        os.path.join(
            OUTDIR,
            "significanceAnalysis",
            "significanceAnalysis_{timepoints}-{groups}",
            "{mag}_two_sample_test_unpaired.tsv.gz",
        ),
        os.path.join(
            OUTDIR,
            "significanceAnalysis",
            "significanceAnalysis_{timepoints}-{groups}",
            "{mag}_two_sample_test_paired.tsv.gz",
        ),
        os.path.join(
            OUTDIR,
            "significanceAnalysis",
            "significanceAnalysis_{timepoints}-{groups}",
            "{mag}_single_sample_test.tsv.gz",
        ),
        os.path.join(
            OUTDIR,
            "significanceAnalysis",
            "significanceAnalysis_{timepoints}-{groups}",
            "{mag}_nucleotide_frequencies.tsv.gz",
        ),
    params:
        outDir=os.path.join(
            OUTDIR,
            "significanceAnalysis",
            "significanceAnalysis_{timepoints}-{groups}",
        ),
        scriptPath=config["scripts"]["significance_test"],
        fasta=config["fasta"],
        breath_threshold=config.get("breath_threshold", 0.1),
        min_sample_num=config.get("min_sample_num", 4),
    threads: config["cpus"]["significance_test"]
    log:
        os.path.join(
            config["logDir"],
            "significance_analysis",
            "{timepoints}-{groups}-{mag}.log",
        ),
    shell:
        """
        python {params.scriptPath} \
            --magID {wildcards.mag} \
            --mag_metadata_file {input.mag_metadata_file} \
            --fasta {params.fasta} \
            --breath_threshold {params.breath_threshold} \
            --min_sample_num {params.min_sample_num} \
            --cpus {threads} \
            --output_dir {params.outDir} \
            > {log} 2>&1
        """
